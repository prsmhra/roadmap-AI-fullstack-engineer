<!DOCTYPE html>
<html>
<head>
    <meta charset='utf-8'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <title>AI-FullStack Engineer</title>
    <meta name='viewport' content='width=device-width, initial-scale=1'>
    <link rel='stylesheet' type='text/css' media='screen' href='main.css'>
    <script src='main.js'></script>
     
</head>
<body>
    <div class="container">
        <nav class="navbar">
            <div class="logo-div">
                <a href=".">
                    <svg class="fill-current sm:w-20 w-16" fill="none" height="78" viewBox="0 0 229 78" width="229" xmlns="http://www.w3.org/2000/svg"><path d="M55.7568 8.69113C54.2925 7.56473 52.4851 6.96568 50.6368 7.00152H47.6672C41.1238 11.9116 33.961 15.9411 26.368 18.9823C18.8365 22.0851 11.7043 26.0684 5.12 30.8607C1.92512 33.7177 0.06656 37.7829 0 42.0735C0.37888 43.6965 1.52576 45.0329 3.072 45.6575C4.4544 46.1183 5.888 46.6815 7.2704 47.2447C21.2634 53.1839 34.4064 59.5686 46.6944 66.3935C48.3226 67.5762 49.8637 68.8767 51.3024 70.2847C52.2394 70.6943 53.248 70.9043 54.272 70.8991C56.7962 70.9196 59.2435 70.0492 61.184 68.4415C63.1552 67.0335 64.1997 64.6527 63.8976 62.2463C63.9795 60.4799 62.9299 58.8569 61.2864 58.2015L40.0896 48.8831C33.0547 45.8982 26.2195 42.478 19.6096 38.6431C24.2432 32.8729 30.4794 28.5977 37.5296 26.3551C44.5389 24.0972 51.0054 20.421 56.5248 15.5519C57.3184 14.789 57.7638 13.7343 57.7536 12.6335C57.7178 11.0873 56.9856 9.63321 55.7568 8.69113Z" fill="currentColor"></path><path d="M173.192 8.69113C174.657 7.56473 176.464 6.96568 178.312 7.00152H181.282C187.825 11.9116 194.988 15.9411 202.581 18.9823C210.112 22.0851 217.245 26.0684 223.829 30.8607C227.024 33.7177 228.882 37.7829 228.949 42.0735C228.57 43.6965 227.423 45.0329 225.877 45.6575C224.495 46.1183 223.061 46.6815 221.679 47.2447C207.686 53.1839 194.543 59.5686 182.255 66.3935C180.626 67.5762 179.085 68.8767 177.647 70.2847C176.71 70.6943 175.701 70.9043 174.677 70.8991C172.153 70.9196 169.705 70.0492 167.765 68.4415C165.794 67.0335 164.749 64.6527 165.051 62.2463C164.969 60.4799 166.019 58.8569 167.663 58.2015L188.859 48.8831C195.894 45.8982 202.729 42.478 209.339 38.6431C204.706 32.8729 198.47 28.5977 191.419 26.3551C184.41 24.0972 177.944 20.421 172.424 15.5519C171.631 14.789 171.185 13.7343 171.195 12.6335C171.231 11.0873 171.963 9.63321 173.192 8.69113Z" fill="currentColor"></path><path d="M93.3949 21.24C93.5946 21.24 93.7943 21.2451 93.9939 21.2502C94.1731 21.2451 94.3523 21.24 94.5264 21.24C97.752 21.24 100.916 22.1821 103.62 23.9638C107.367 27.5273 109.226 32.6474 108.637 37.7879C108.637 45.6215 106.384 50.8438 101.776 53.6086C99.4775 54.9091 96.8919 55.6106 94.25 55.6566C94.2397 55.6566 94.2346 55.6566 94.2243 55.6566C90.2051 55.6566 86.4164 53.7571 84.01 50.5366C81.1684 47.0704 79.3917 42.8566 78.89 38.4022C77.8557 33.6713 79.3251 28.7408 82.7811 25.3462C85.6893 22.6992 89.4781 21.24 93.3949 21.24ZM93.7892 42.4982C96.6154 42.4982 98.9092 40.2045 98.9092 37.3782C98.9092 34.552 96.6154 32.2582 93.7892 32.2582C90.9629 32.2582 88.6692 34.552 88.6692 37.3782C88.6692 40.2045 90.9629 42.4982 93.7892 42.4982ZM93.3949 11C86.9028 11 80.6871 13.4064 75.8896 17.7737C75.7923 17.8608 75.7002 17.9478 75.608 18.04C69.7303 23.8102 67.201 32.0022 68.7728 40.0509C69.5613 46.2205 72.0343 52.0163 75.9511 56.8598C80.2775 62.5226 87.0871 65.8966 94.2243 65.8966C98.7555 65.8198 103.041 64.6525 106.809 62.5277C106.886 62.4816 106.968 62.4355 107.045 62.3894C112.375 59.1894 118.713 52.4259 118.872 38.3357C119.604 30.2512 116.568 22.1462 110.675 16.545C110.235 16.1251 109.753 15.7462 109.246 15.4134C104.864 12.5309 99.7744 11.0051 94.5264 11.0051C94.3575 11.0051 94.1885 11.0051 94.0195 11.0102C93.8096 11 93.6048 11 93.3949 11Z" fill="currentColor" clip-rule="evenodd" fill-rule="evenodd"></path><path d="M103.62 23.9638C100.768 22.0899 97.4039 21.1376 93.9939 21.2502C89.8621 21.0915 85.8378 22.5661 82.7811 25.3462C79.3251 28.7408 77.8557 33.6713 78.89 38.4022C79.3917 42.8566 81.1684 47.0704 84.01 50.5366C86.4215 53.7674 90.2205 55.6669 94.25 55.6566C96.8919 55.6106 99.4775 54.9091 101.776 53.6086C106.384 50.8438 108.637 45.6215 108.637 37.7879C109.226 32.6474 107.367 27.5325 103.62 23.9638ZM93.7892 42.4982C90.9629 42.4982 88.6692 40.2045 88.6692 37.3782C88.6692 34.552 90.9629 32.2582 93.7892 32.2582C96.6154 32.2582 98.9092 34.552 98.9092 37.3782C98.9092 40.2045 96.6154 42.4982 93.7892 42.4982Z" fill="currentColor" clip-rule="evenodd" fill-rule="evenodd"></path><path d="M114.316 37.2695C114.316 48.0391 105.585 56.7695 94.8156 56.7695C84.046 56.7695 75.3156 48.0391 75.3156 37.2695C75.3156 26.5 84.046 17.7695 94.8156 17.7695C105.585 17.7695 114.316 26.5 114.316 37.2695Z" fill="currentColor"></path><path d="M149.112 31.671C148.297 38.2955 147.461 57.4944 147.273 67.341C147.232 69.5043 145.832 71.4364 143.676 71.6269C139.382 72.0066 133.814 71.3815 130.964 69.7944C129.748 68.6547 129.164 66.9933 129.396 65.3419C129.688 63.9143 129.917 62.3912 130.121 60.9124C131.974 45.8246 133.016 31.25 133.249 17.1958C133.039 15.1945 132.684 13.2095 132.184 11.2596C132.297 10.2434 132.62 9.26487 133.136 8.38062C134.381 6.1844 136.358 4.50014 138.721 3.62348C140.926 2.62037 143.51 2.90621 145.443 4.37102C147.013 5.18328 150.254 8.74899 150 10.5L149.112 31.671Z" fill="currentColor"></path></svg>
                </a>
            </div>
            <div class="nav-links">
                <a href="#">home</a>
                <a href="#">Explore</a>
            </div>
        </nav>

        <div class="main-content">
            <span id="scalability">Scalability</span>
            <h1>Scalability for Dummies</h1>
            <span id="time">September 24, 2023</span>
            <p>  
                Just recently I was asked what it would take to make a web service massively scalable. My answer was lengthy and maybe it is also for other people interesting. So I share it with you here in my blog and split it into parts to make it easier to read. New parts are released on a regular basis. Have fun and your comments are always welcomed!
            </p>
            <h2>Part 1 - Clones</h2>
            <p>Public servers of a scalable web service are hidden behind a load balancer. This load balancer evenly distributes load (requests from your users) onto your group/cluster of application servers. That means that if, for example, user Steve interacts with your service, he may be served at his first request by server 2, then with his second request by server 9 and then maybe again by server 2 on his third request.</p>
            <p>
                Steve should always get the same results of his request back, independent what server he “landed on”. That leads to the first golden rule for scalability: every server contains exactly the same codebase and does not store any user-related data, like sessions or profile pictures, on local disc or memory.
            </p>
            <p>
                Sessions need to be stored in a centralized data store which is accessible to all your application servers. It can be an external database or an external persistent cache, like Redis. An external persistent cache will have better performance than an external database. By external I mean that the data store does not reside on the application servers. Instead, it is somewhere in or near the data center of your application servers.
            </p>
            <p>
                But what about deployment? How can you make sure that a code change is sent to all your servers without one server still serving old code? This tricky problem is fortunately already solved by the great tool Capistrano. It requires some learning, especially if you are not into Ruby on Rails, but it is definitely both the effort.
            </p>
            <p>
                After “outsourcing” your sessions and serving the same codebase from all your servers, you can now create an image file from one of these servers (AWS calls this AMI - Amazon Machine Image.) Use this AMI as a “super-clone” that all your new instances are based upon. Whenever you start a new instance/clone, just do an initial deployment of your latest code and you are ready!
            </p>
            <h2>
                Part 2 - Database
            </h2>
            <p>
                After following Part 1, your servers can now horizontally scale and you can already serve thousands of concurrent requests. But somewhere down the road your application gets slower and slower and finally breaks down. The reason: your database. It’s MySQL, isn’t it?
            </p>
            <p>
                Now the required changes are more radical than just adding more cloned servers and may even require some boldness. In the end, you can choose from 2 paths:
            </p>
            <p><strong>Path #1</strong>  is to stick with MySQL and keep the “beast” running. Hire a database administrator (DBA,) tell him to do master-slave replication (read from slaves, write to master) and upgrade your master server by adding RAM, RAM and more RAM. In some months, your DBA will come up with words like “sharding”, “denormalization” and “SQL tuning” and will look worried about the necessary overtime during the next weeks. At that point every new action to keep your database running will be more expensive and time consuming than the previous one. You might have been better off if you had chosen Path #2 while your dataset was still small and easy to migrate.</p>
            <p><strong>Path #2</strong> means to denormalize right from the beginning and include no more Joins in any database query. You can stay with MySQL, and use it like a NoSQL database, or you can switch to a better and easier to scale NoSQL database like MongoDB or CouchDB. Joins will now need to be done in your application code. The sooner you do this step the less code you will have to change in the future. But even if you successfully switch to the latest and greatest NoSQL database and let your app do the dataset-joins, soon your database requests will again be slower and slower. You will need to introduce a cache.</p>
            <h3>Part 3 - Cache</h3>
            <p>After following Part 2 above, you now have a scalable database solution. You have no fear of storing terabytes anymore and the world is looking fine. But just for you. Your users still have to suffer slow page requests when a lot of data is fetched from the database. The solution is the implementation of a cache.</p>
            <p>With “cache” I always mean in-memory caches like Memcached or Redis. Please never do file-based caching, it makes cloning and auto-scaling of your servers just a pain.</p>
            <p>But back to in-memory caches. A cache is a simple key-value store and it should reside as a buffering layer between your application and your data storage. Whenever your application has to read data it should at first try to retrieve the data from your cache. Only if it’s not in the cache should it then try to get the data from the main data source. Why should you do that? Because a cache is lightning-fast. It holds every dataset in RAM and requests are handled as fast as technically possible. For example, Redis can do several hundreds of thousands of read operations per second when being hosted on a standard server. Also writes, especially increments, are very, very fast. Try that with a database!</p>
            <p>There are 2 patterns of caching your data. An old one and a new one:</p>
            <h3>#1 - Cached Database Queries</h3>
            <p>That’s still the most commonly used caching pattern. Whenever you do a query to your database, you store the result dataset in cache. A hashed version of your query is the cache key. The next time you run the query, you first check if it is already in the cache. The next time you run the query, you check at first the cache if there is already a result. This pattern has several issues. The main issue is the expiration. It is hard to delete a cached result when you cache a complex query (who has not?). When one piece of data changes (for example a table cell) you need to delete all cached queries who may include that table cell. You get the point?</p>
            <h3>#2 - Cached Objects</h3>
            <p>That’s my strong recommendation and I always prefer this pattern. In general, see your data as an object like you already do in your code (classes, instances, etc.). Let your class assemble a dataset from your database and then store the complete instance of the class or the assembed dataset in the cache. Sounds theoretical, I know, but just look how you normally code. You have, for example, a class called “Product” which has a property called “data”. It is an array containing prices, texts, pictures, and customer reviews of your product. The property “data” is filled by several methods in the class doing several database requests which are hard to cache, since many things relate to each other. Now, do the following: when your class has finished the “assembling” of the data array, directly store the data array, or better yet the complete instance of the class, in the cache! This allows you to easily get rid of the object whenever something did change and makes the overall operation of your code faster and more logical.</p>
            <p>And the best part: it makes asynchronous processing possible! Just imagine an army of worker servers who assemble your objects for you! The application just consumes the latest cached object and nearly never touches the databases anymore!</p>

            <p>
                Some ideas of objects to cache:
                <ul>
                    <li>user sessions (never use the database!)</li>
                    <li>fully rendered blog articles</li>
                    <li>activity streams</li>
                    <li>user<->friend relationships</li>
                </ul>
            </p>
            <p>
                As you maybe already realized, I am a huge fan of caching. It is easy to understand, very simple to implement and the result is always breathtaking. In general, I am more a friend of Redis than Memcached, because I love the extra database-features of Redis like persistence and the built-in data structures like lists and sets. With Redis and a clever key’ing there may be a chance that you even can get completly rid of a database. But if you just need to cache, take Memcached, because it scales like a charm.
            </p>
            <h3>Part 4 - Asynchronism</h3>
            <p>Let’s imagine that you want to buy bread at your favorite bakery. So you go into the bakery, ask for a loaf of bread, but there is no bread there! Instead, you are asked to come back in 2 hours when your ordered bread is ready. That’s annoying, isn’t it?</p>
            <p>
                To avoid such a “please wait a while” - situation, asynchronism needs to be done. And what’s good for a bakery, is maybe also good for your web service or web app.
            </p>
            <p>
                In general, there are two ways / paradigms asynchronism can be done.
            </p>
            <h4>Async #1</h4>
            <p>
                Let’s stay in the former bakery picture. The first way of async processing is the “bake the breads at night and sell them in the morning” way. No waiting time at the cash register and a happy customer. Referring to a web app this means doing the time-consuming work in advance and serving the finished work with a low request time.
            </p>
            <p>
                Very often this paradigm is used to turn dynamic content into static content. Pages of a website, maybe built with a massive framework or CMS, are pre-rendered and locally stored as static HTML files on every change. Often these computing tasks are done on a regular basis, maybe by a script which is called every hour by a cronjob. This pre-computing of overall general data can extremely improve websites and web apps and makes them very scalable and performant. Just imagine the scalability of your website if the script would upload these pre-rendered HTML pages to AWS S3 or Cloudfront or another Content Delivery Network! Your website would be super responsive and could handle millions of visitors per hour!
            </p>
            <h4>Async #2</h4>
            <p>Back to the bakery. Unfortunately, sometimes customers has special requests like a birthday cake with “Happy Birthday, Steve!” on it. The bakery can not foresee these kind of customer wishes, so it must start the task when the customer is in the bakery and tell him to come back at the next day. Refering to a web service that means to handle tasks asynchronously.</p>
            <p>Here is a typical workflow:</p>
            <p>A user comes to your website and starts a very computing intensive task which would take several minutes to finish. So the frontend of your website sends a job onto a job queue and immediately signals back to the user: your job is in work, please continue to the browse the page. The job queue is constantly checked by a bunch of workers for new jobs. If there is a new job then the worker does the job and after some minutes sends a signal that the job was done. The frontend, which constantly checks for new “job is done” - signals, sees that the job was done and informs the user about it. I know, that was a very simplified example.</p>
            <p>If you now want to dive more into the details and actual technical design, I recommend you take a look at the first 3 tutorials on the RabbitMQ website. RabbitMQ is one of many systems which help to implement async processing. You could also use ActiveMQ or a simple Redis list. The basic idea is to have a queue of tasks or jobs that a worker can process. Asynchronism seems complicated, but it is definitely worth your time to learn about it and implement it yourself. Backends become nearly infinitely scalable and frontends become snappy which is good for the overall user experience. </p>
            <p>If you do something time-consuming, try to do it always asynchronously.</p>
            <p>And with that this guide comes to an end. Stay tuned for more on scalability.</p>
        </div>

        <footer>© All rights reserved — cs.fyi</footer>

    </div>
</body>
</html>